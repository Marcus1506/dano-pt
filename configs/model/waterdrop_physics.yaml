_target_: src.models.physics.PhysicsLitModule
num_classes: ${vars.num_classes}

latent_model:
  _target_: src.models.components.latent.transformer.Transformer
  _partial_: True
  latent_dim: ${vars.latent_dim}
  transformer_dim: 192
  transformer_depth: 12
  transformer_attn_heads: 3
  input_proj: False
  output_proj: False
  input_ln: True
  output_ln: True
  init_weights: torch
  init_last_proj_zero: True
  full_residual: True
  condition_dim: 768

optimizer:
  _target_: torch.optim.AdamW
  _partial_: True
  lr: 0.0001
  weight_decay: 0.05

scheduler:
  _target_: src.modules.schedulers.LinearWarmupCosineAnnealingLR
  _partial_: true
  warmup_epochs: 1
  max_epochs: ${trainer.max_epochs}
  min_lr: 1e-6
  last_epoch: -1

loss_function:
  _target_: torch.nn.MSELoss

first_stage_model_ckpt: logs\train\runs\2025-08-21_17-10-50\waterdrop\i2evdm2j\checkpoints\epoch=27-step=418740.ckpt
first_stage_model_wandb_entity: 'learning1566'
first_stage_model_wandb_id: 'i2evdm2j'
first_stage_model_wandb_project: 'waterdrop'